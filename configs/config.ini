[settings]
dataset_name = None
dataset_path = data/raw/
metadata_path = data/metadata/

output_dir = trained_models/
samples_dir = test_samples/
loss_logs_dir = training_logs
cache_dir = None
logging_dir = logs
pretrained_model_path = None
resolution = 64
hidden_dims = [64, 128, 256]
n_timesteps = 1000
n_inference_timesteps = 250
use_flash_attn = True

train_batch_size = 16
eval_batch_size = 16
num_epochs = 10
save_model_steps = 1000
gradient_accumulation_steps = 1
learning_rate = 0.001
lr_scheduler = cosine
lr_warmup_steps = 500
adam_beta1 = 0.9
adam_beta2 = 0.99
adam_weight_decay = 0.0
use_clip_grad = True
fp16_precision = True
gamma = 0.996
guidance_scale = 1.0
