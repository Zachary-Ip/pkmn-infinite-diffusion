[settings]
dataset_name = None
dataset_path = data/raw/
metadata_path = data/metadata/

output_dir = trained_models/
samples_dir = test_samples/
loss_logs_dir = training_logs
cache_dir = None
logging_dir = logs
resolution = 256
hidden_dims = [16, 32, 32]
n_timesteps = 500
n_inference_timesteps = 100
use_flash_attn = True

train_batch_size = 1
eval_batch_size = 1
num_epochs = 5
save_model_steps = 2500
gradient_accumulation_steps = 4
learning_rate = 0.0005
lr_scheduler = cosine
lr_warmup_steps = 1000
adam_beta1 = 0.9
adam_beta2 = 0.99
adam_weight_decay = 0.000001
use_clip_grad = True
fp16_precision = True
gamma = 0.996
guidance_scale = 5.0
