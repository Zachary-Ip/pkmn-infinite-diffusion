{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make sure that Data can be loaded and transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from omegaconf import OmegaConf\n",
    "import os\n",
    "from PIL import Image, UnidentifiedImageError\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Transformations (Resize + Normalize)\n",
    "config = OmegaConf.load('configs/train.yaml')\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((config.model.image_size, config.model.image_size)),  # Resize images to 64x64\n",
    "    transforms.ToTensor(),  # Convert to tensor\n",
    "    transforms.Normalize((0.5,), (0.5,)),  # Normalize to [-1,1]\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset with exception\n",
    "\n",
    "# Custom Dataset (Simple Version)\n",
    "# class PokemonDataset(Dataset):\n",
    "#     def __init__(self, image_folder, transform=None):\n",
    "#         self.image_folder = image_folder\n",
    "#         self.image_files = [f for f in os.listdir(image_folder) if f.endswith(\".png\")]\n",
    "#         self.transform = transform\n",
    "\n",
    "#     def __len__(self):\n",
    "#         return len(self.image_files)\n",
    "\n",
    "#     def __getitem__(self, idx):\n",
    "#         img_path = os.path.join(self.image_folder, self.image_files[idx])\n",
    "#         image = Image.open(img_path).convert(\"RGB\")\n",
    "#         if self.transform:\n",
    "#             image = self.transform(image)\n",
    "#         return image\n",
    "\n",
    "class PokemonDataset(Dataset):\n",
    "    def __init__(self, image_folder, transform=None):\n",
    "        self.image_folder = image_folder\n",
    "        self.image_files = self.get_valid_images(image_folder)\n",
    "        self.transform = transform\n",
    "\n",
    "    def get_valid_images(self, folder):\n",
    "        valid_images = []\n",
    "        for f in os.listdir(folder):\n",
    "            if f.endswith(\".png\"):\n",
    "                img_path = os.path.join(folder, f)\n",
    "                try:\n",
    "                    with Image.open(img_path) as img:\n",
    "                        img.verify()  # Verify if the image is corrupted\n",
    "                    valid_images.append(f)\n",
    "                except (IOError, UnidentifiedImageError):\n",
    "                    print(f\"Skipping corrupted file: {f}\")\n",
    "        return valid_images\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.image_folder, self.image_files[idx])\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping corrupted file: 92.248b.png\n",
      "Skipping corrupted file: 92.247a.png\n",
      "Skipping corrupted file: 374.235.png\n",
      "Skipping corrupted file: 57.150.png\n",
      "Skipping corrupted file: 25.151a.png\n",
      "Skipping corrupted file: 429.74.png\n",
      "Skipping corrupted file: 144.367.png\n",
      "Skipping corrupted file: 281.144a.png\n",
      "Skipping corrupted file: 334.38.png\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Load Dataset\n",
    "dataset = PokemonDataset(\"data/raw/\", transform=transform)\n",
    "# dataloader = DataLoader(dataset, batch_size=32, num_workers=8, pin_memory=True, shuffle=True)\n",
    "\n",
    "dataloader = DataLoader(dataset, batch_size=128, num_workers=os.cpu_count() // 2, pin_memory=True, shuffle=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-1.0..1.0].\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Test: Load & Display a Sample Image\n",
    "sample_image = dataset[-1].permute(1, 2, 0).numpy()  # Convert from tensor (C, H, W) to (H, W, C)\n",
    "plt.imshow(sample_image)\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"Sample Pokémon Sprite\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic version of a forward pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NoiseScheduler:\n",
    "    '''\n",
    "    We define βₜ (the noise variance) and αₜ (related to βₜ):\n",
    "\n",
    "    βₜ (beta_t) controls how much noise is added at each step.\n",
    "    αₜ (alpha_t) and ᾱₜ (cumulative alpha) determine the transition from x₀ to xₜ.\n",
    "    '''\n",
    "    def __init__(self, num_timesteps=1000, beta_start=1e-4, beta_end=0.02, device=\"cpu\"):\n",
    "        self.num_timesteps = num_timesteps\n",
    "        self.device = device  # Store device info\n",
    "\n",
    "        # Initialize tensors\n",
    "        self.beta_t = torch.linspace(beta_start, beta_end, num_timesteps, device=device)\n",
    "        self.alpha_t = 1.0 - self.beta_t\n",
    "        self.alpha_bar_t = torch.cumprod(self.alpha_t, dim=0)\n",
    "\n",
    "    def get_variance(self, t):\n",
    "        \"\"\"Returns beta_t and alpha_bar_t at timestep t (ensuring they're on the correct device).\"\"\"\n",
    "        return self.beta_t[t], self.alpha_bar_t[t]\n",
    "\n",
    "# Initialize Scheduler\n",
    "scheduler = NoiseScheduler(num_timesteps=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_diffusion(x_0, t, scheduler):\n",
    "    \"\"\"Adds noise to image x_0 at timestep t\"\"\"\n",
    "    beta_t, alpha_bar_t = scheduler.get_variance(t)\n",
    "    # Ensure `alpha_bar_t` has the right shape for broadcasting\n",
    "    alpha_bar_t = alpha_bar_t.view(-1, 1, 1, 1)  # Reshape to [batch_size, 1, 1, 1]\n",
    "\n",
    "    beta_t, alpha_bar_t = beta_t.to(x_0.device), alpha_bar_t.to(x_0.device)\n",
    "\n",
    "    noise = torch.randn_like(x_0, device=x_0.device)  # Sample Gaussian noise\n",
    "    \n",
    "    # Apply diffusion\n",
    "    noisy_x = torch.sqrt(alpha_bar_t) * x_0 + torch.sqrt(1 - alpha_bar_t) * noise\n",
    "    return noisy_x, noise  # Return both the noisy image and the actual noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x300 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Select a sample image from the dataset\n",
    "sample_image = dataset[0].unsqueeze(0)  # Add batch dimension\n",
    "\n",
    "# Pick timesteps to visualize\n",
    "timesteps = [0, 50, 200, 500, 999]\n",
    "\n",
    "plt.figure(figsize=(15, 3))\n",
    "for i, t in enumerate(timesteps):\n",
    "    noisy_image, _ = forward_diffusion(sample_image, t, scheduler)\n",
    "    noisy_image = noisy_image.squeeze(0).permute(1, 2, 0).numpy()  # Convert to displayable format\n",
    "    noisy_image = np.clip(noisy_image, 0, 1)  # Ensure valid pixel values\n",
    "\n",
    "    plt.subplot(1, len(timesteps), i + 1)\n",
    "    plt.imshow(noisy_image)\n",
    "    plt.axis(\"off\")\n",
    "    plt.title(f\"t = {t}\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the U-Net model for denoising"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class SimpleUNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleUNet, self).__init__()\n",
    "        \n",
    "        # Encoding path (downsampling)\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(128, 256, kernel_size=3, padding=1)\n",
    "        \n",
    "        # Bottleneck\n",
    "        self.conv_mid = nn.Conv2d(256, 256, kernel_size=3, padding=1)\n",
    "        \n",
    "        # Decoding path (upsampling)\n",
    "        self.deconv3 = nn.ConvTranspose2d(256, 128, kernel_size=2, stride=2)\n",
    "        self.deconv2 = nn.ConvTranspose2d(128, 64, kernel_size=2, stride=2)\n",
    "        self.deconv1 = nn.ConvTranspose2d(64, 3, kernel_size=2, stride=2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Encoder\n",
    "        x1 = F.relu(self.conv1(x))\n",
    "        x2 = F.relu(self.conv2(F.max_pool2d(x1, 2)))\n",
    "        x3 = F.relu(self.conv3(F.max_pool2d(x2, 2)))\n",
    "\n",
    "        # Bottleneck\n",
    "        x_mid = F.relu(self.conv_mid(F.max_pool2d(x3, 2)))\n",
    "        \n",
    "        # Decoder\n",
    "        x_up3 = F.relu(self.deconv3(F.interpolate(x_mid, scale_factor=2, mode='nearest')))\n",
    "        x_up2 = F.relu(self.deconv2(F.interpolate(x_up3, scale_factor=2, mode='nearest')))\n",
    "        x_up1 = torch.tanh(self.deconv1(F.interpolate(x_up2, scale_factor=2, mode='nearest')))  # [-1,1] range\n",
    "\n",
    "        return x_up1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update SimpleUNet\n",
    "\n",
    "class SimpleUNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleUNet, self).__init__()\n",
    "\n",
    "        # Encoding path\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, padding=1)  \n",
    "        self.conv2 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(128, 256, kernel_size=3, padding=1)\n",
    "\n",
    "        # Bottleneck\n",
    "        self.conv_mid = nn.Conv2d(256, 256, kernel_size=3, padding=1)\n",
    "\n",
    "        # Decoding path (match encoder's channel sizes)\n",
    "        self.deconv3 = nn.ConvTranspose2d(256, 128, kernel_size=2, stride=2)  # 256 → 128\n",
    "        self.deconv2 = nn.ConvTranspose2d(128, 64, kernel_size=2, stride=2)    # 128 → 64\n",
    "        self.deconv1 = nn.ConvTranspose2d(64, 3, kernel_size=2, stride=2)      # 64 → 3\n",
    "\n",
    "        # Normalize\n",
    "        self.bn = nn.BatchNorm2d(out_channels)  # Batch Normalization\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Encoder\n",
    "        x1 = F.relu(self.conv1(x))  # (3 → 64)\n",
    "        x2 = F.relu(self.conv2(F.max_pool2d(x1, 2)))  # (64 → 128)\n",
    "        x3 = F.relu(self.conv3(F.max_pool2d(x2, 2)))  # (128 → 256)\n",
    "\n",
    "        # Bottleneck\n",
    "        x_mid = F.relu(self.conv_mid(F.max_pool2d(x3, 2)))  # (256 → 256)\n",
    "\n",
    "        # Decoder (skip connections)\n",
    "        x_up3 = F.relu(self.deconv3(x_mid))  # (256 → 128)\n",
    "\n",
    "        x_up2 = F.relu(self.deconv2(x_up3))  # (256 → 128 → 64)\n",
    "        x_up1 = self.deconv1(x_up2)  # (128 → 64 → 3)\n",
    "        x_up1 = torch.tanh(x_up1)  # Ensure output is in [-1,1]\n",
    "\n",
    "        # Ensure output size matches input\n",
    "        x_up1 = F.interpolate(x_up1, size=(32, 32), mode='bilinear', align_corners=False)\n",
    "\n",
    "        return x_up1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Net v3 with batch normalization\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class SimpleUNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleUNet, self).__init__()\n",
    "\n",
    "        # Encoding path\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(64)  # BatchNorm after conv1\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(128)  # BatchNorm after conv2\n",
    "        \n",
    "        self.conv3 = nn.Conv2d(128, 256, kernel_size=3, padding=1)\n",
    "        self.bn3 = nn.BatchNorm2d(256)  # BatchNorm after conv3\n",
    "\n",
    "        # Bottleneck\n",
    "        self.conv_mid = nn.Conv2d(256, 256, kernel_size=3, padding=1)\n",
    "        self.bn_mid = nn.BatchNorm2d(256)  # BatchNorm in bottleneck\n",
    "\n",
    "        # Decoding path\n",
    "        self.deconv3 = nn.ConvTranspose2d(256, 128, kernel_size=2, stride=2)\n",
    "        self.bn_deconv3 = nn.BatchNorm2d(128)  # BatchNorm in decoder\n",
    "        \n",
    "        self.deconv2 = nn.ConvTranspose2d(128, 64, kernel_size=2, stride=2)\n",
    "        self.bn_deconv2 = nn.BatchNorm2d(64)  # BatchNorm in decoder\n",
    "        \n",
    "        self.deconv1 = nn.ConvTranspose2d(64, 3, kernel_size=2, stride=2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Encoder\n",
    "        x1 = F.relu(self.bn1(self.conv1(x)))  # (3 → 64)\n",
    "        x2 = F.relu(self.bn2(self.conv2(F.max_pool2d(x1, 2))))  # (64 → 128)\n",
    "        x3 = F.relu(self.bn3(self.conv3(F.max_pool2d(x2, 2))))  # (128 → 256)\n",
    "\n",
    "        # Bottleneck\n",
    "        x_mid = F.relu(self.bn_mid(self.conv_mid(F.max_pool2d(x3, 2))))  # (256 → 256)\n",
    "\n",
    "        # Decoder (skip connections)\n",
    "        x_up3 = F.relu(self.bn_deconv3(self.deconv3(x_mid)))  # (256 → 128)\n",
    "        x_up2 = F.relu(self.bn_deconv2(self.deconv2(x_up3)))  # (128 → 64)\n",
    "        x_up1 = self.deconv1(x_up2)  # (64 → 3)\n",
    "        x_up1 = torch.tanh(x_up1)  # Ensure output is in [-1,1]\n",
    "\n",
    "        # Ensure output size matches input\n",
    "        x_up1 = F.interpolate(x_up1, size=(32, 32), mode='bilinear', align_corners=False)\n",
    "\n",
    "        return x_up1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model to predict the noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'models'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moptim\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01moptim\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01munet\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnet\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Initialize model, optimizer, and loss function\u001b[39;00m\n\u001b[1;32m      4\u001b[0m device \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Documents/Github/pkmn-infinite-diffusion/src/models/unet.py:7\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m functional \u001b[38;5;28;01mas\u001b[39;00m F\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01meinops\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Rearrange\n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mattention\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Attention\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mget_downsample_layer\u001b[39m(in_dim, hidden_dim, is_last):\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_last:\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'models'"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "import src.models.unet as net\n",
    "# Initialize model, optimizer, and loss function\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# model = SimpleUNet().to(device)\n",
    "model = u.UNet().to(device)\n",
    "scheduler = NoiseScheduler(num_timesteps=1000, device=device)\n",
    "\n",
    "# Move scheduler's tensors to the correct device\n",
    "scheduler.beta_t = scheduler.beta_t.to(device)\n",
    "scheduler.alpha_t = scheduler.alpha_t.to(device)\n",
    "scheduler.alpha_bar_t = scheduler.alpha_bar_t.to(device)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), weight_decay=1e-4, lr=1e-4) # 1e-3 was causing exploding weights\n",
    "criterion = nn.MSELoss()  # Predicting noise, so we use MSE loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define checkpoint directory\n",
    "checkpoint_dir = \"src/models/\"\n",
    "os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "\n",
    "# Save model\n",
    "def save_model(model, epoch):\n",
    "    checkpoint_path = os.path.join(checkpoint_dir, f\"model_epoch_{epoch}.pth\")\n",
    "    torch.save(model.state_dict(), checkpoint_path)\n",
    "    print(f\"Checkpoint saved: {checkpoint_path}\")\n",
    "\n",
    "def load_model(model, checkpoint_path):\n",
    "    model.load_state_dict(torch.load(checkpoint_path))\n",
    "    model.eval()  # Set to evaluation mode\n",
    "    print(f\"Loaded model from {checkpoint_path}\")\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rakurai/.cache/pypoetry/virtualenvs/pkmn-infinite-diffusion-sgfbErnI-py3.10/lib/python3.10/site-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "/home/rakurai/.cache/pypoetry/virtualenvs/pkmn-infinite-diffusion-sgfbErnI-py3.10/lib/python3.10/site-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "/home/rakurai/.cache/pypoetry/virtualenvs/pkmn-infinite-diffusion-sgfbErnI-py3.10/lib/python3.10/site-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "/home/rakurai/.cache/pypoetry/virtualenvs/pkmn-infinite-diffusion-sgfbErnI-py3.10/lib/python3.10/site-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "/home/rakurai/.cache/pypoetry/virtualenvs/pkmn-infinite-diffusion-sgfbErnI-py3.10/lib/python3.10/site-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "/home/rakurai/.cache/pypoetry/virtualenvs/pkmn-infinite-diffusion-sgfbErnI-py3.10/lib/python3.10/site-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "/home/rakurai/.cache/pypoetry/virtualenvs/pkmn-infinite-diffusion-sgfbErnI-py3.10/lib/python3.10/site-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "/home/rakurai/.cache/pypoetry/virtualenvs/pkmn-infinite-diffusion-sgfbErnI-py3.10/lib/python3.10/site-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Batch 0, Loss: 1.3477\n",
      "Epoch 1/10, Batch 1000, Loss: 0.9695\n",
      "Checkpoint saved: src/models/model_epoch_0.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rakurai/.cache/pypoetry/virtualenvs/pkmn-infinite-diffusion-sgfbErnI-py3.10/lib/python3.10/site-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "/home/rakurai/.cache/pypoetry/virtualenvs/pkmn-infinite-diffusion-sgfbErnI-py3.10/lib/python3.10/site-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "/home/rakurai/.cache/pypoetry/virtualenvs/pkmn-infinite-diffusion-sgfbErnI-py3.10/lib/python3.10/site-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "/home/rakurai/.cache/pypoetry/virtualenvs/pkmn-infinite-diffusion-sgfbErnI-py3.10/lib/python3.10/site-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "/home/rakurai/.cache/pypoetry/virtualenvs/pkmn-infinite-diffusion-sgfbErnI-py3.10/lib/python3.10/site-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "/home/rakurai/.cache/pypoetry/virtualenvs/pkmn-infinite-diffusion-sgfbErnI-py3.10/lib/python3.10/site-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "/home/rakurai/.cache/pypoetry/virtualenvs/pkmn-infinite-diffusion-sgfbErnI-py3.10/lib/python3.10/site-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "/home/rakurai/.cache/pypoetry/virtualenvs/pkmn-infinite-diffusion-sgfbErnI-py3.10/lib/python3.10/site-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10, Batch 0, Loss: 0.9316\n",
      "Epoch 2/10, Batch 1000, Loss: 0.8692\n",
      "Checkpoint saved: src/models/model_epoch_1.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rakurai/.cache/pypoetry/virtualenvs/pkmn-infinite-diffusion-sgfbErnI-py3.10/lib/python3.10/site-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "/home/rakurai/.cache/pypoetry/virtualenvs/pkmn-infinite-diffusion-sgfbErnI-py3.10/lib/python3.10/site-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "/home/rakurai/.cache/pypoetry/virtualenvs/pkmn-infinite-diffusion-sgfbErnI-py3.10/lib/python3.10/site-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "/home/rakurai/.cache/pypoetry/virtualenvs/pkmn-infinite-diffusion-sgfbErnI-py3.10/lib/python3.10/site-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "/home/rakurai/.cache/pypoetry/virtualenvs/pkmn-infinite-diffusion-sgfbErnI-py3.10/lib/python3.10/site-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "/home/rakurai/.cache/pypoetry/virtualenvs/pkmn-infinite-diffusion-sgfbErnI-py3.10/lib/python3.10/site-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "/home/rakurai/.cache/pypoetry/virtualenvs/pkmn-infinite-diffusion-sgfbErnI-py3.10/lib/python3.10/site-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "/home/rakurai/.cache/pypoetry/virtualenvs/pkmn-infinite-diffusion-sgfbErnI-py3.10/lib/python3.10/site-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10, Batch 0, Loss: 0.8519\n",
      "Epoch 3/10, Batch 1000, Loss: 0.8322\n",
      "Checkpoint saved: src/models/model_epoch_2.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rakurai/.cache/pypoetry/virtualenvs/pkmn-infinite-diffusion-sgfbErnI-py3.10/lib/python3.10/site-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "/home/rakurai/.cache/pypoetry/virtualenvs/pkmn-infinite-diffusion-sgfbErnI-py3.10/lib/python3.10/site-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "/home/rakurai/.cache/pypoetry/virtualenvs/pkmn-infinite-diffusion-sgfbErnI-py3.10/lib/python3.10/site-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "/home/rakurai/.cache/pypoetry/virtualenvs/pkmn-infinite-diffusion-sgfbErnI-py3.10/lib/python3.10/site-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "/home/rakurai/.cache/pypoetry/virtualenvs/pkmn-infinite-diffusion-sgfbErnI-py3.10/lib/python3.10/site-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "/home/rakurai/.cache/pypoetry/virtualenvs/pkmn-infinite-diffusion-sgfbErnI-py3.10/lib/python3.10/site-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "/home/rakurai/.cache/pypoetry/virtualenvs/pkmn-infinite-diffusion-sgfbErnI-py3.10/lib/python3.10/site-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "/home/rakurai/.cache/pypoetry/virtualenvs/pkmn-infinite-diffusion-sgfbErnI-py3.10/lib/python3.10/site-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/10, Batch 0, Loss: 0.8196\n",
      "Epoch 4/10, Batch 1000, Loss: 0.8049\n",
      "Checkpoint saved: src/models/model_epoch_3.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rakurai/.cache/pypoetry/virtualenvs/pkmn-infinite-diffusion-sgfbErnI-py3.10/lib/python3.10/site-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "/home/rakurai/.cache/pypoetry/virtualenvs/pkmn-infinite-diffusion-sgfbErnI-py3.10/lib/python3.10/site-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "/home/rakurai/.cache/pypoetry/virtualenvs/pkmn-infinite-diffusion-sgfbErnI-py3.10/lib/python3.10/site-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "/home/rakurai/.cache/pypoetry/virtualenvs/pkmn-infinite-diffusion-sgfbErnI-py3.10/lib/python3.10/site-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "/home/rakurai/.cache/pypoetry/virtualenvs/pkmn-infinite-diffusion-sgfbErnI-py3.10/lib/python3.10/site-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "/home/rakurai/.cache/pypoetry/virtualenvs/pkmn-infinite-diffusion-sgfbErnI-py3.10/lib/python3.10/site-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "/home/rakurai/.cache/pypoetry/virtualenvs/pkmn-infinite-diffusion-sgfbErnI-py3.10/lib/python3.10/site-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "/home/rakurai/.cache/pypoetry/virtualenvs/pkmn-infinite-diffusion-sgfbErnI-py3.10/lib/python3.10/site-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10, Batch 0, Loss: 0.8084\n",
      "Epoch 5/10, Batch 1000, Loss: 0.7829\n",
      "Checkpoint saved: src/models/model_epoch_4.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rakurai/.cache/pypoetry/virtualenvs/pkmn-infinite-diffusion-sgfbErnI-py3.10/lib/python3.10/site-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "/home/rakurai/.cache/pypoetry/virtualenvs/pkmn-infinite-diffusion-sgfbErnI-py3.10/lib/python3.10/site-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "/home/rakurai/.cache/pypoetry/virtualenvs/pkmn-infinite-diffusion-sgfbErnI-py3.10/lib/python3.10/site-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "/home/rakurai/.cache/pypoetry/virtualenvs/pkmn-infinite-diffusion-sgfbErnI-py3.10/lib/python3.10/site-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "/home/rakurai/.cache/pypoetry/virtualenvs/pkmn-infinite-diffusion-sgfbErnI-py3.10/lib/python3.10/site-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "/home/rakurai/.cache/pypoetry/virtualenvs/pkmn-infinite-diffusion-sgfbErnI-py3.10/lib/python3.10/site-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "/home/rakurai/.cache/pypoetry/virtualenvs/pkmn-infinite-diffusion-sgfbErnI-py3.10/lib/python3.10/site-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "/home/rakurai/.cache/pypoetry/virtualenvs/pkmn-infinite-diffusion-sgfbErnI-py3.10/lib/python3.10/site-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/10, Batch 0, Loss: 0.7830\n",
      "Epoch 6/10, Batch 1000, Loss: 0.7776\n",
      "Checkpoint saved: src/models/model_epoch_5.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rakurai/.cache/pypoetry/virtualenvs/pkmn-infinite-diffusion-sgfbErnI-py3.10/lib/python3.10/site-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "/home/rakurai/.cache/pypoetry/virtualenvs/pkmn-infinite-diffusion-sgfbErnI-py3.10/lib/python3.10/site-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "/home/rakurai/.cache/pypoetry/virtualenvs/pkmn-infinite-diffusion-sgfbErnI-py3.10/lib/python3.10/site-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "/home/rakurai/.cache/pypoetry/virtualenvs/pkmn-infinite-diffusion-sgfbErnI-py3.10/lib/python3.10/site-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "/home/rakurai/.cache/pypoetry/virtualenvs/pkmn-infinite-diffusion-sgfbErnI-py3.10/lib/python3.10/site-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "/home/rakurai/.cache/pypoetry/virtualenvs/pkmn-infinite-diffusion-sgfbErnI-py3.10/lib/python3.10/site-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "/home/rakurai/.cache/pypoetry/virtualenvs/pkmn-infinite-diffusion-sgfbErnI-py3.10/lib/python3.10/site-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "/home/rakurai/.cache/pypoetry/virtualenvs/pkmn-infinite-diffusion-sgfbErnI-py3.10/lib/python3.10/site-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/10, Batch 0, Loss: 0.7663\n",
      "Epoch 7/10, Batch 1000, Loss: 0.7734\n",
      "Checkpoint saved: src/models/model_epoch_6.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rakurai/.cache/pypoetry/virtualenvs/pkmn-infinite-diffusion-sgfbErnI-py3.10/lib/python3.10/site-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "/home/rakurai/.cache/pypoetry/virtualenvs/pkmn-infinite-diffusion-sgfbErnI-py3.10/lib/python3.10/site-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "/home/rakurai/.cache/pypoetry/virtualenvs/pkmn-infinite-diffusion-sgfbErnI-py3.10/lib/python3.10/site-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "/home/rakurai/.cache/pypoetry/virtualenvs/pkmn-infinite-diffusion-sgfbErnI-py3.10/lib/python3.10/site-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "/home/rakurai/.cache/pypoetry/virtualenvs/pkmn-infinite-diffusion-sgfbErnI-py3.10/lib/python3.10/site-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "/home/rakurai/.cache/pypoetry/virtualenvs/pkmn-infinite-diffusion-sgfbErnI-py3.10/lib/python3.10/site-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "/home/rakurai/.cache/pypoetry/virtualenvs/pkmn-infinite-diffusion-sgfbErnI-py3.10/lib/python3.10/site-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "/home/rakurai/.cache/pypoetry/virtualenvs/pkmn-infinite-diffusion-sgfbErnI-py3.10/lib/python3.10/site-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/10, Batch 0, Loss: 0.7588\n",
      "Epoch 8/10, Batch 1000, Loss: 0.7554\n",
      "Checkpoint saved: src/models/model_epoch_7.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rakurai/.cache/pypoetry/virtualenvs/pkmn-infinite-diffusion-sgfbErnI-py3.10/lib/python3.10/site-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "/home/rakurai/.cache/pypoetry/virtualenvs/pkmn-infinite-diffusion-sgfbErnI-py3.10/lib/python3.10/site-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "/home/rakurai/.cache/pypoetry/virtualenvs/pkmn-infinite-diffusion-sgfbErnI-py3.10/lib/python3.10/site-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "/home/rakurai/.cache/pypoetry/virtualenvs/pkmn-infinite-diffusion-sgfbErnI-py3.10/lib/python3.10/site-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "/home/rakurai/.cache/pypoetry/virtualenvs/pkmn-infinite-diffusion-sgfbErnI-py3.10/lib/python3.10/site-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "/home/rakurai/.cache/pypoetry/virtualenvs/pkmn-infinite-diffusion-sgfbErnI-py3.10/lib/python3.10/site-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "/home/rakurai/.cache/pypoetry/virtualenvs/pkmn-infinite-diffusion-sgfbErnI-py3.10/lib/python3.10/site-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "/home/rakurai/.cache/pypoetry/virtualenvs/pkmn-infinite-diffusion-sgfbErnI-py3.10/lib/python3.10/site-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/10, Batch 0, Loss: 0.7566\n",
      "Epoch 9/10, Batch 1000, Loss: 0.7562\n",
      "Checkpoint saved: src/models/model_epoch_8.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rakurai/.cache/pypoetry/virtualenvs/pkmn-infinite-diffusion-sgfbErnI-py3.10/lib/python3.10/site-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "/home/rakurai/.cache/pypoetry/virtualenvs/pkmn-infinite-diffusion-sgfbErnI-py3.10/lib/python3.10/site-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "/home/rakurai/.cache/pypoetry/virtualenvs/pkmn-infinite-diffusion-sgfbErnI-py3.10/lib/python3.10/site-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "/home/rakurai/.cache/pypoetry/virtualenvs/pkmn-infinite-diffusion-sgfbErnI-py3.10/lib/python3.10/site-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "/home/rakurai/.cache/pypoetry/virtualenvs/pkmn-infinite-diffusion-sgfbErnI-py3.10/lib/python3.10/site-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "/home/rakurai/.cache/pypoetry/virtualenvs/pkmn-infinite-diffusion-sgfbErnI-py3.10/lib/python3.10/site-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "/home/rakurai/.cache/pypoetry/virtualenvs/pkmn-infinite-diffusion-sgfbErnI-py3.10/lib/python3.10/site-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "/home/rakurai/.cache/pypoetry/virtualenvs/pkmn-infinite-diffusion-sgfbErnI-py3.10/lib/python3.10/site-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/10, Batch 0, Loss: 0.7583\n",
      "Epoch 10/10, Batch 1000, Loss: 0.7548\n",
      "Checkpoint saved: src/models/model_epoch_9.pth\n"
     ]
    }
   ],
   "source": [
    "# Training Loop\n",
    "num_epochs = 10  # Keep it small for now\n",
    "\n",
    "# Define checkpoint directory\n",
    "checkpoint_dir = \"src/models/\"\n",
    "os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "\n",
    "\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for batch_idx, imgs in enumerate(dataloader):\n",
    "        imgs = imgs.to(device)\n",
    "        # Sample a random timestep for each image\n",
    "        t = torch.randint(0, scheduler.num_timesteps, (imgs.shape[0],), device=device)\n",
    "        # Apply forward diffusion\n",
    "        noisy_imgs, noise = forward_diffusion(imgs, t, scheduler)\n",
    "        # Predict noise using U-Net\n",
    "        noise_pred = model(noisy_imgs)\n",
    "        if torch.isnan(noise_pred).any():\n",
    "                print(f\"NaN detected in model output at timestep {t}\")\n",
    "                break\n",
    "        \n",
    "        # Compute loss\n",
    "        loss = criterion(noise_pred, noise)\n",
    "        \n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=0.5) \n",
    "        optimizer.step()\n",
    "\n",
    "        # Print loss occasionally\n",
    "        if batch_idx % 1000 == 0:\n",
    "            print(f\"Epoch {epoch+1}/{num_epochs}, Batch {batch_idx}, Loss: {loss.item():.4f}\")\n",
    "\n",
    "    save_model(model, epoch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from src/models/model_epoch_9.pth\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import torchvision.utils as vutils\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Configuration\n",
    "output_dir = \"results\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "image_size = 32  # Adjust if needed\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Function to find the latest checkpoint\n",
    "def find_latest_checkpoint(checkpoint_dir):\n",
    "    checkpoints = glob.glob(os.path.join(checkpoint_dir, \"model_epoch_*.pth\"))\n",
    "    if not checkpoints:\n",
    "        raise FileNotFoundError(\"No checkpoints found!\")\n",
    "    latest_checkpoint = max(checkpoints, key=os.path.getctime)\n",
    "    return latest_checkpoint\n",
    "\n",
    "# Load latest model\n",
    "latest_checkpoint = find_latest_checkpoint(checkpoint_dir)\n",
    "model = SimpleUNet().to(device)\n",
    "model.load_state_dict(torch.load(latest_checkpoint, map_location=device))\n",
    "model.eval()\n",
    "print(f\"Loaded model from {latest_checkpoint}\")\n",
    "for name, param in model.named_parameters():\n",
    "    if torch.isnan(param).any():\n",
    "        print(f\"NaN detected in {name}\")\n",
    "\n",
    "# Sampling process\n",
    "def generate_images(num_samples=8):\n",
    "    with torch.no_grad():\n",
    "        # Start with pure noise\n",
    "        x_t = torch.randn((num_samples, 3, image_size, image_size), device=device)\n",
    "        \n",
    "        for t in tqdm(reversed(range(scheduler.num_timesteps))):\n",
    "            beta_t, alpha_bar_t = scheduler.get_variance(t)\n",
    "\n",
    "            if torch.isnan(beta_t).any() or torch.isnan(alpha_bar_t).any():\n",
    "                print(f\"NaN detected in scheduler at timestep {t} -> beta_t: {beta_t}, alpha_bar_t: {alpha_bar_t}\")\n",
    "                break  # Stop execution immediately\n",
    "\n",
    "            noise_pred = model(x_t)\n",
    "\n",
    "            if torch.isnan(noise_pred).any():\n",
    "                print(f\"NaN detected in model output at timestep {t}\")\n",
    "                break\n",
    "\n",
    "            # x_t = (x_t - torch.sqrt(1 - alpha_bar_t) * noise_pred) / torch.sqrt(alpha_bar_t)\n",
    "\n",
    "            # Avoid dividing by 0 error\n",
    "            eps = 1e-7  # Small constant to prevent instability\n",
    "            x_t = (x_t - torch.sqrt(torch.clamp(1 - alpha_bar_t, min=eps)) * noise_pred) / torch.sqrt(torch.clamp(alpha_bar_t, min=eps))\n",
    "            if x_t.abs().max() > 1e3:  # Arbitrary threshold, adjust as needed\n",
    "                print(f\"Warning: x_t exploding at timestep {t}, max value: {x_t.abs().max().item()}\")\n",
    "                break\n",
    "\n",
    "            if torch.isnan(x_t).any():\n",
    "                print(f\"NaN detected in x_t at timestep {t}\")\n",
    "                break\n",
    "\n",
    "            if t > 0:\n",
    "                noise = torch.randn_like(x_t)\n",
    "                # x_t += torch.sqrt(beta_t) * noise\n",
    "                # avoid dividing by 0 error\n",
    "                x_t += torch.sqrt(torch.clamp(beta_t, min=eps)) * noise\n",
    "\n",
    "        \n",
    "        # Normalize images to [0,1]\n",
    "        generated_images = (x_t + 1) / 2  # Assuming tanh output\n",
    "        print(\"Min:\", generated_images.min().item(), \"Max:\", generated_images.max().item())\n",
    "\n",
    "        return generated_images\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00, 112.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: x_t exploding at timestep 998, max value: 86455.78125\n",
      "Min: -41792.23046875 Max: 43228.390625\n",
      "Generated samples saved to results/generated_samples.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Generate images\n",
    "samples = generate_images(num_samples=8)\n",
    "vutils.save_image(samples, os.path.join(output_dir, \"generated_samples.png\"))\n",
    "print(f\"Generated samples saved to {output_dir}/generated_samples.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pkmn-infinite-diffusion",
   "language": "python",
   "name": "pkmn-infinite-diffusion"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
